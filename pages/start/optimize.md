tags: start

# Optimize a Model

[TOC]

## Overview

In the [previous section](/start/index.md), you use Guild to run
`train.py` --- a sample training script. In this section, you run the
same script with different hyperparameter values to find lower values
of `loss`. This process is known as [hyperparameter optimization
->](term:https://en.wikipedia.org/wiki/Hyperparameter_optimization),
or hyperparameter *tuning*.

Guild supports hyperparameter optimization using different search
methods:

- Manual search
- [Grid Search ->](term:grid-search)
- [Random search ->](term:random-search)
- [Bayesian optimization ->](term:bayesian-optimization)

For review, here's the loss function used in `train.py`:

``` python
loss = (np.sin(5 * x) * (1 - np.tanh(x ** 2)) + np.random.randn() * noise)
```

The relationship between `x` and `loss` is plotted below. Optimal
values for `x` are around -0.3.

![](/assets/img/bayesian-optimization.png)

^ Plot of `x` on the horizontal axis to `loss` on the vertical axis
  [^hparam-plot]

[^hparam-plot]: Image credit: [*Bayesian optimization with skopt*
    ->](https://scikit-optimize.github.io/auto_examples/bayesian-optimization.html)

In a real scenario, we don't know the optimal hyperparameter values
--- we need to search for them.

## Manual Search

When experimenting with hyperparameters, it's often useful to start
with values based on prior experience or intuition.

Guild lets you run multiple trials in a batch by specifying them as a
list in the form ``[VAL1,VAL2,...VALN]``.

Run three trials of `train.py` using different values for `x`:

``` command
guild run train.py x=[-1,0,1]
```

``` output
You are about to run train.py as a batch (3 trials)
  noise: 0.1
  x: [-1, 0, 1]
Continue? (Y/n)
```

Press `Enter` to start the batch.

Guild runs `train.py` three times, once for each specified value of
`x`.

Show the runs:

``` command
guild runs
```

``` output
[1:1933bdcb]  train.py   2020-01-14 09:38:15  completed  noise=0.1 x=1
[2:83dc048d]  train.py   2020-01-14 09:38:14  completed  noise=0.1 x=0
[3:468bb240]  train.py   2020-01-14 09:38:14  completed  noise=0.1 x=-1
[4:bfcff413]  train.py+  2020-01-14 09:38:13  completed
[5:68f4da74]  train.py   2020-01-14 08:42:54  completed  noise=0.1 x=0.1
```

Runs 1 through 3 are the *trial* runs generated by the command. Run 4
is a [batch run](term:batch). Batch runs are responsible for
generating trials and are denoted using ``+`` in their name.

### Compare Runs

To compare `loss` across runs, use the [compare](cmd:compare) command:

``` command
guild compare --min loss
```

Guild starts an interactive application that lets you browse
experiment results. Runs with lower `loss` appear at the top due to
``--min loss``. Use your arrow keys to navigate. Press `1` to sort by
the current column in ascending order or `2` to sort in descending
order. Press `?` for a list of supported commands.

![](/assets/img/compare-start.png)

^ Compare experiment results --- press `?` for a list of commands, `q`
  to exit

Exit *Guild Compare* by pressing `q`.

Next, run *four* trials --- one for for each unique combination of the
specified flag values:

``` command
guild run train.py x=[-0.5,0.5] noise=[0.1,0.2]
```

``` output
You are about to run train.py as a batch (4 trials)
  noise: [0.1, 0.2]
  x: [-0.5, 0.5]
Continue? (Y/n)
```

Press `Enter` to start the batch.

Show the top-3 best runs:

``` command
guild compare --table --min loss --top 3
```

The `--table` option tells Guild to show results without running in
interactive mode. The `--top` option tells Guild to show only the
top-N runs based on the sort order.

Note that runs where `x` is `-0.5` have the lowest `loss`. This is
consistent with our expectation from the plot above.

### View Runs in TensorBoard

View runs in [TensorBoard](ref:tensorboard) using the
[tensorboard](cmd:tensorboard) command:

``` command
guild tensorboard
```

Guild starts TensorBoard and opens a new tab in your
browser. TensorBoard board is used to view run results, including
scalars, images, embeddings, and hyperparameters.

Select the **HPARAMS** tab and then select **PARALLEL COORDINATES
VIEW**.

![](/assets/img/tb-hparams.png)

^ Compare runs using **Parallel Coordinates View**

The *Parallel Coordinates View* highlights runs that perform better
along various axes. Click-and-drag along the `loss` axis to highlight
runs with the lowest values.

!!! highlight
    Guild automatically generates *HParam* summaries from
    Guild runs to simply the process of comparing runs in TensorBoard.

To continue with this guide using the same terminal, stop TensorBoard
by typing `Ctrl-C` in the terminal. Alternatively, open a new command
terminal, leaving TensorBoard running in the background and continue
the steps below.

## Grid Search

[Grid search](term:grid-search) is a systematic search across a subset
of hyperparameter space. Guild supports a special [flag sequence
syntax](term:flag-sequence-function) for specifying value
ranges. Ranges are specified using the format
``FUNCTION[START:END:STEP_OR_COUNT]`` where `FUNCTION` is the type of
sequence and `START` and `END` mark the start and end of the sequence
respectively. `STEP_OR_COUNT` is the range step or value count,
depending on the function used.

Use [`linspace`](/flags.md#linspace) to run four trials where `x` is
evenly spaced between `-0.6` and `0.6`:

``` command
guild run train.py x=linspace[-0.6:0.6:4]
```

``` output
You are about to run train.py as a batch (max 20 trials, minimize loss)
  noise: 0.1
  x: [-0.6, -0.2, 0.2, 0.6]
Continue? (Y/n)
```

Guild expands the function `linspace[-0.6:0.6:4]` to the sequence of
values `[-0.6, -0.2, 0.2, 0.6]`. The value `4` indicates how many
values appear in the list.

Press `Enter` to start the batch.

Guild runs trials for each value of `x` generated by the `linspace`
function.

!!! tip
    Use sequence functions for multiple flags to expand a grid
    search to the catesian product of each set of values.

## Random Search

Guild supports [random search](term:random-search) over a both uniform
and log-uniform distributions.

Search space is specified by [special flag
functions](/flags.md#search-space-functions), which include
[`uniform`](/flags.md#uniform) and
[`loguniform`](/flags.md#loguniform). The `uniform` function name may
be omitted.

To search over a uniformly distributed range of values, specify a flag
value in the format `[MIN:MAX]`. By default, Guild runs 20 trials
using randomly chosen values within the specified range. Use
`--max-trials` to specify the number of trials to run.

Start a random search over `x` with 5 trials:

``` command
guild run train.py x=[-2.0:2.0] --max-trials 5
```

``` output
You are about to run train.py with random search (max 5 trials, minimize loss)
  noise: 0.1
  x: [-2.0:2.0]
Continue? (Y/n)
```

Press `Enter` to start the batch.

Guild runs `train.py` five times using randomly sampled values for `x`
from `-2.0` to `2.0`.

## Bayesian Optimization

Bayesian optimization uses light-weight probabilistic models to
suggest hyperparameter values believed to optimize an *objective*
based on previous results.

By default, Guild attempts to minimize `loss`, which is logged by
`train.py`. If the script used a different objective, specify it using
`--mininize` or `--maximize` options for the [run](cmd:run) command.

Run 10 trials using the [`gp`](/reference/optimizers.md#gp) optimizer,
which uses Bayesian optimization with *gaussian processes*:

``` command
guild run train.py x=[-2.0:2.0] --optimizer gp --max-trials 10
```

``` output
You are about to run train.py with 'skopt:gp' optimizer (max 10 trials, minimize loss)
  noise: 0.1
  x: [-2.0:2.0]
Optimizer flags:
  acq-func: gp_hedge
  kappa: 1.96
  noise: gaussian
  random-starts: 3
  xi: 0.05
Continue? (Y/n)
```

Press `Enter` to start the batch.

The `gp` optimizer seeds the batch with three random starts. After the
third random start, the optimizer uses previous results to suggest
candidates for `x` between `-2.0` and `2.0` to minimize `loss`.

For list of available optimizes, see
[Optimizers](/reference/optimizers.md).

### Restart Batch to Continue Optimization

Guild optimizers use previous results from trials *of the same
batch*. If you want to continue a search for hyperparameters using
previous results, you must restart the batch run.

To restart a run, you need the target run ID.

To get the run ID of the `gp` batch, run:

``` command
guid select -o train.py+gp
```

Guild prints the ID of the last `gp` batch run. Copy this value for
the next command.

Restart the batch to generate another ten trials, replacing ``<batch
run ID>`` below with ID from the previous command:

``` command
guild run -Fo random-starts=0 --restart <batch run ID>
```

``` output
You are about to start <batch run ID> (train.py) with 'skopt:gp' optimizer (max 10 trials)
  noise: 0.1
  x: [-2.0:2.0]
Optimizer flags:
  acq-func: gp_hedge
  kappa: 1.96
  noise: gaussian
  random-starts: 0
  xi: 0.05
Continue? (Y/n)
```

!!! tip
    If you are running Linux, macOS, or another POSIX environment,
    you can use [command substitution
    ->](https://www.gnu.org/software/bash/manual/html_node/Command-Substitution.html)
    and the [select](cmd:select) command to specify a run ID
    argument. For example, ``guild run --restart $(guild select -o
    train.py+gp)`` will replace the argument ``$(...)`` with the run
    ID returned by `guild select`.

Press `Enter` to restart the batch.

Guild generates another ten trials for the batch. Guild uses the
previous trials generated earlier as inputs to the optimization.

The option ``-Fo random-starts=0`` is an *optimizer flag* that sets
the number of random starts to 0.

### Evaluate Bayesian Optimization Results

Run [Guild Compare](ref:guild-compare) on the last 20 runs to evaluate
the results of the Bayesian optimization:

``` command
guild compare 1:20
```

By default, Guild shows runs ordered by start time starting with the
latest run first. Note the values for `x` that the `gp` optimizer
suggests. If the optimizer is effective in finding values for `x` that
minimize `loss`, you will see more values around `-0.3` toward the top
of the list (i.e. the more recent runs, which benefit from more trial
data).

Press `q` to exit Guild Compare.

You can also use TensorBoard to evaluate optimization results.

Start TensorBoard to view the last 20 runs:

``` command
guild tensorboard 1:20
```

Guild starts TensorBoard and opens a new browser tab.

Select the **HPARAMS** tag and then select **SCATTER PLOT MATRIX
VIEW**.

TensorBoard displays scatter plots of hypermaraters and metrics.

In the left side panel, *deselect* the following hyperparameters:

- `noise`
- `sourcecode`

In the same panel, *deselect* the following metrics:

- `time`

TensorBoard displays a plot of `loss` against `x`. Each point on the
plot represents a trial. Given the known relationship between `loss`
and `x` (see plot above), the Bayesian optimizer should spend more
time exporing values for `x` around `-0.3`. This will appear as a
cluster of trials along the bottom of the plot between `-0.4` and
`-0.2`.

![](/assets/img/tb-hparams-scatter.png)

^ Plot `loss` against `x` to evaluate the Bayesian optimization
  results

Return to the command terminal and press `Ctrl-C` to stop TensorBoard.

## Summary

In this section, you use various techniques to run `train.py`.

!!! highlight
    Run experiments using a variety of methods for exploring
    different hyperparameters including grid search, random search,
    and Bayesian optimization.

In the next section, you learn how to manage runs.
